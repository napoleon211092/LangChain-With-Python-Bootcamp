{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a14785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1f3f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = api_key\n",
    "llm = ChatOpenAI(openai_api_key=api_key,\n",
    "                 model='gpt-4-0125-preview',\n",
    "                 temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "038cba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4810c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ---> Tools Docstring ---> pick tool ---> Actiob ---> Observation --->\n",
    "@tool\n",
    "def coolest_guy(text: str) -> str:\n",
    "    '''Return the name of the coolest person in the universe.\n",
    "    Expects an input of empty string '' and returns the \n",
    "    name of the coolest person in the universe\n",
    "    '''\n",
    "    return \"Lam Nguyen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2b4470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(['wikipedia','llm-math'],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "460dba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a6bbdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis question is highly subjective and depends on personal opinions. There's no definitive answer to who the \"coolest\" person in the universe is, as people have different criteria for what makes someone cool. However, I can provide information on a person who is often regarded as cool in popular culture or has made significant contributions to society, science, entertainment, or another field. Given the nature of the question, I'll choose someone who is widely recognized and has had a notable impact in their field.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Most influential people in history\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: The 100: A Ranking of the Most Influential Persons in History\n",
      "Summary: The 100: A Ranking of the Most Influential Persons in History is a 1978 book by the American author Michael H. Hart. Published by his father's publishing house, it was his first book and was reprinted in 1992 with revisions. It is a ranking of the 100 people who, according to Hart, most influenced human history. Unlike various other rankings at the time, Hart was not attempting to rank on \"greatness\" as a criterion, but rather whose actions most changed the course of human history.\n",
      "\n",
      "Page: Time 100\n",
      "Summary: Time 100 is an annual listicle of the 100 most influential people in the world, assembled by the American news magazine Time. First published in 1999 as the result of a debate among American academics, politicians, and journalists, the list is now a highly publicized annual event. Appearing on the list is often seen as an honor, and Time makes it clear that entrants are recognized for changing the world, regardless of the consequences of their actions. The final list of influential individuals is exclusively chosen by Time editors, with nominations coming from the Time 100 alumni and the magazine's international writing staff. Only the winner of the Reader's Poll, conducted days before the official list is revealed, is chosen by the general public. The corresponding commemorative gala is held annually in Manhattan.\n",
      "In 2019, Time began publishing the Time 100 Next list, which \"spotlights 100 rising stars who are shaping the future of business, entertainment, sports, politics, science, health and more.\"\n",
      "\n",
      "\n",
      "\n",
      "Page: The 500 Most Influential Muslims\n",
      "Summary: The 500 Most Influential Muslims (also known as The Muslim 500) is an annual publication first published in 2009, which ranks the most influential Muslims in the world.\n",
      "The publication is compiled by the Royal Islamic Strategic Studies Centre in Amman, Jordan. The report is issued annually in cooperation with Prince Al-Waleed Bin Talal Center for Muslim-Christian Understanding at Georgetown University in the United States.Qatar's Emir Tamim bin Hamid Al-Thani took first place in the 2022 edition. He was followed by King Salman of Saudi Arabia, Iranian Supreme Leader Ali Khamenei and Turkey's President Recep Tayyip ErdoÄŸan. King Abdullah II of Jordan, Pakistani scholar Muhammad Taqi Usmani, King Mohammed VI of Morocco, President of the UAE Mohammed bin Zayed Al Nahyan, and Iranian cleric Ali al-Sistani are also among the top 9 in the list.Critics have noted that its top 50 list gives more weight to political leaders, who due to the nature of political systems in Middle East enjoy considerable clout and influence in the regional politics. As such the influence of individuals listed in the top 50 owes much to the fact of their existence in the political spectrum.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mGiven the information from the searches, it's clear that \"coolness\" is subjective and can vary widely depending on the criteria used. The lists provided offer insights into individuals who have had significant impacts on history, current global influence, or are rising stars in various fields. Since the question of who is the \"coolest\" person in the universe is subjective and cannot be answered definitively, I will select a person who is often regarded as cool in popular culture and has made significant contributions to their field. Considering the broad appeal and significant impact on technology and culture, someone like Elon Musk, who has been influential in the fields of technology, space exploration, and renewable energy, could be considered \"cool\" by many. However, it's important to note that this is just one perspective, and opinions on who the coolest person is will vary greatly.\n",
      "\n",
      "Final Answer: The question of who is the coolest person in the universe is highly subjective and depends on personal opinions and criteria for \"coolness.\" While there's no definitive answer, individuals like Elon Musk are often regarded as cool in popular culture due to their significant contributions to technology, space exploration, and renewable energy. However, opinions will vary greatly.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is the coolest person in the universe?',\n",
       " 'output': 'The question of who is the coolest person in the universe is highly subjective and depends on personal opinions and criteria for \"coolness.\" While there\\'s no definitive answer, individuals like Elon Musk are often regarded as cool in popular culture due to their significant contributions to technology, space exploration, and renewable energy. However, opinions will vary greatly.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Who is the coolest person in the universe?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73b5b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(['wikipedia','llm-math'],llm=llm)\n",
    "tools = tools + [coolest_guy]\n",
    "#tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fea6ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f496ce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find out who the coolest person in the universe is, I should use the coolest_guy tool.\n",
      "Action: coolest_guy\n",
      "Action Input: ''\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mLam Nguyen\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The coolest person in the universe is Lam Nguyen.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is the coolest person in the universe?',\n",
       " 'output': 'The coolest person in the universe is Lam Nguyen.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Who is the coolest person in the universe?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7db560cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I cannot provide real-time information or updates, including the current time. My responses are based on a fixed dataset up to my last training cut-off in early 2023, and I don't have access to live data or the ability to interact with the world in real-time.`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\agents\\agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;31m# Call the LLM to see what to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1125\u001b[1;33m             output = self.agent.plan(\n\u001b[0m\u001b[0;32m   1126\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\agents\\agent.py\u001b[0m in \u001b[0;36mplan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0mfull_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"Action\\s*\\d*\\s*:[\\s]*(.*?)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             raise OutputParserException(\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \u001b[1;34mf\"Could not parse LLM output: `{text}`\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `I cannot provide real-time information or updates, including the current time. My responses are based on a fixed dataset up to my last training cut-off in early 2023, and I don't have access to live data or the ability to interact with the world in real-time.`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19504\\3347527141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Do you know what time it is right now?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             outputs = (\n\u001b[1;32m--> 156\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\agents\\agent.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1389\u001b[0m         \u001b[1;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1391\u001b[1;33m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[0;32m   1392\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\agents\\agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[0;32m   1096\u001b[0m         return self._consume_next_step(\n\u001b[1;32m-> 1097\u001b[1;33m             [\n\u001b[0m\u001b[0;32m   1098\u001b[0m                 \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 for a in self._iter_next_step(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\agents\\agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[0;32m   1096\u001b[0m         return self._consume_next_step(\n\u001b[1;32m-> 1097\u001b[1;33m             [\n\u001b[0m\u001b[0;32m   1098\u001b[0m                 \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 for a in self._iter_next_step(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\agents\\agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1134\u001b[0m                 \u001b[0mraise_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1136\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1137\u001b[0m                     \u001b[1;34m\"An output parsing error occurred. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m                     \u001b[1;34m\"In order to pass this error back to the agent and have it try \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I cannot provide real-time information or updates, including the current time. My responses are based on a fixed dataset up to my last training cut-off in early 2023, and I don't have access to live data or the ability to interact with the world in real-time.`"
     ]
    }
   ],
   "source": [
    "agent.invoke(\"Do you know what time it is right now?\")\n",
    "# Can't answer because\n",
    "# Could not parse LLM output: `I cannot provide real-time information or updates, including the current time. My responses are based on a fixed dataset up to my last training cut-off in early 2023, and I don't have access to live data or the ability to interact with the world in real-time.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b91ff99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "@tool\n",
    "def get_current_time(text: str) -> str:\n",
    "    '''Returns the current time. Use this for any questions regrading the current time.\n",
    "     Input is an empty string and the current time is return in a string format.\n",
    "     Only use this function for the current times, other time related questions should use another tool\n",
    "    '''\n",
    "    return str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae8e34b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the get_current_time tool to find out the current time.\n",
      "Action: get_current_time\n",
      "Action Input: ''\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2024-03-29 23:23:26.265151\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The current time is 2024-03-29 23:23:26.265151.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you know what time it is right now?',\n",
       " 'output': 'The current time is 2024-03-29 23:23:26.265151.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = initialize_agent(tools+[get_current_time],\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True)\n",
    "agent.invoke(\"Do you know what time it is right now?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
