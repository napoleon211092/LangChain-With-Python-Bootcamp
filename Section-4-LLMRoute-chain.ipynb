{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaf13088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b3ab127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = api_key\n",
    "llm = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cace54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student ask physics\n",
    "# Normal student: \"how does a magnet work?\"\n",
    "# PhD student: \"Explain Feynman diagram?\"\n",
    "# INPUT → ROUTER → LLM decides chain → Chain → OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9132716",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginner_template='''You are a physics teacher who is really focused on beginners\n",
    "and explaining complex concepts in simple to understand terms.\n",
    "You assume no prior knowledge. Here is your question:\\n{input}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5d826ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_template = '''\n",
    "You are physics professor who explains physics topics to advanced audience members.\n",
    "You can assume anyone you answer has a PhD in Physics.\n",
    "Here is your question:\\n{input}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e062caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUTE PROMPT INFORMATION\n",
    "# [] NAME, DESCRIPTION, TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "234871f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'beginner physics',\n",
       "  'description': 'Answer basic physics questions',\n",
       "  'template': 'You are a physics teacher who is really focused on beginners\\nand explaining complex concepts in simple to understand terms.\\nYou assume no prior knowledge. Here is your question:\\n{input}'},\n",
       " {'name': 'advanced physics',\n",
       "  'description': 'Answer advanced physics questions',\n",
       "  'template': '\\nYou are physics professor who explains physics topics to advanced audience members.\\nYou can assume anyone you answer has a PhD in Physics.\\nHere is your question:\\n{input}\\n'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_infos = [\n",
    "    {'name':'beginner physics',\n",
    "     'description':'Answer basic physics questions',\n",
    "     'template': beginner_template,},\n",
    "    {'name': 'advanced physics',\n",
    "     'description': 'Answer advanced physics questions',\n",
    "     'template': expert_template,},\n",
    "]\n",
    "prompt_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd5c6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a00b3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info['name']\n",
    "    prompt_template = p_info['template']\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm,prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "#destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "018252e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMCHAIN → Template\n",
    "default_prompt = ChatPromptTemplate.from_template('{input}')\n",
    "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a6102b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "236a8f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71b10017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beginner physics:Answer basic physics questions',\n",
       " 'advanced physics:Answer advanced physics questions']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}:{p['description']}\" for p in prompt_infos]\n",
    "destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de0f5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginner physics:Answer basic physics questions\n",
      "advanced physics:Answer advanced physics questions\n"
     ]
    }
   ],
   "source": [
    "destination_str = \"\\n\".join(destinations)\n",
    "print(destination_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18d7045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63bf09cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "beginner physics:Answer basic physics questions\n",
      "advanced physics:Answer advanced physics questions\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destination_str)\n",
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "903e3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = PromptTemplate(template=router_template,\n",
    "                               input_variables=['input'],\n",
    "                               output_parser=RouterOutputParser()\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1c61207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "router_chain = LLMRouterChain.from_llm(llm,router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f454c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "                        destination_chains=destination_chains,\n",
    "                        default_chain=default_chain,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23ae0dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginner physics: {'input': 'how does a magnet work?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how does a magnet work?',\n",
       " 'text': \"Great question! Let's break it down.\\n\\nA magnet is an object that produces a magnetic field around it. This magnetic field is invisible but can still exert a force on other objects that are sensitive to magnets, like other magnets or certain metals.\\n\\nThe reason a magnet can do this is because of the way its atoms are aligned. Inside a magnet, the atoms are all lined up in the same direction, creating a magnetic field. This alignment is what gives the magnet its magnetic properties.\\n\\nWhen you bring a magnet close to another magnet or a piece of magnetic material, like iron, the magnetic field of the first magnet interacts with the magnetic field of the second object. This interaction causes the two objects to either attract or repel each other, depending on how their magnetic fields align.\\n\\nSo, in simple terms, a magnet works by creating a magnetic field that can attract or repel other magnets or certain metals. It all comes down to the alignment of the atoms inside the magnet creating that magnetic field.\"}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke (\"how does a magnet work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f124768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginner physics: {'input': 'how does a nuclear bomb work?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how does a nuclear bomb work?',\n",
       " 'text': 'A nuclear bomb works by utilizing the energy released from splitting atoms. Atoms are made up of a nucleus, which contains protons and neutrons, surrounded by electrons. In a nuclear bomb, a process called nuclear fission is used to split the nucleus of certain atoms, such as uranium or plutonium.\\n\\nWhen the nucleus of an atom is split, a huge amount of energy is released in the form of heat and radiation. This energy is what causes the explosion in a nuclear bomb. The process is highly controlled and amplified through a chain reaction, where each split atom releases more neutrons that go on to split more atoms, leading to a rapid release of energy.\\n\\nThis immense release of energy causes a powerful explosion that can create massive destruction. Nuclear bombs are incredibly dangerous and destructive weapons, which is why there are strict regulations and treaties in place to prevent their use in warfare.'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke (\"how does a nuclear boom work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa9ca03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced physics: {'input': 'Explain the Bekenstein–Hawking formula'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Explain the Bekenstein–Hawking formula',\n",
       " 'text': \"The Bekenstein-Hawking formula relates the entropy of a black hole to its surface area. It is given by:\\n\\nS = A / 4\\n\\nwhere S is the entropy of the black hole, A is the surface area of the black hole's event horizon, and the constant 1/4 is known as the Bekenstein-Hawking entropy.\\n\\nThis formula was proposed by Jacob Bekenstein and further developed by Stephen Hawking as part of their work on black hole thermodynamics. It suggests that black holes possess an entropy, which is a measure of the number of microstates that correspond to a given macroscopic state.\\n\\nThe Bekenstein-Hawking formula has deep implications for our understanding of black holes and their connection to thermodynamics. It suggests that black holes have an entropy that is proportional to their surface area, rather than their volume, which is a key feature of thermodynamic systems.\\n\\nOverall, the Bekenstein-Hawking formula provides important insights into the nature of black holes and their connection to fundamental physics.\"}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke (\"Explain Bekenstein–Hawking formula\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
